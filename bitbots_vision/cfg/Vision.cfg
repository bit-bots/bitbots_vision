#!/usr/bin/env python3
PACKAGE = "bitbots_vision"

from dynamic_reconfigure.parameter_generator_catkin import *
import rospkg

rospack = rospkg.RosPack()
package_path = rospack.get_path('bitbots_vision')

gen = ParameterGenerator()

#########
# Enums #
#########

neural_network_type_enum = gen.enum(
  [
    gen.const("fcnn",str_t, "fcnn", "fcnn classifier"),
    gen.const("yolo_opencv",str_t, "yolo_opencv", "yolo object detection (opencv implementation)"),
    gen.const("yolo_darknet",str_t, "yolo_darknet", "yolo object detection (darknet implementation)"),
    gen.const("yolo_ncs2",str_t, "yolo_ncs2", "yolo object detection (nsc2 usb stick runtime)"),
    gen.const("dummy",str_t, "dummy", "no balls will be detected")
  ],
  "An enum to set the ball classifier")

field_boundary_detector_enum = gen.enum(
  [
    gen.const("iteration",str_t, "iteration", "searches from the top until green"),
    gen.const("dynamic",str_t, "dynamic", "uses head_joint_state messages to switch between methods"),
    gen.const("reversed",str_t, "reversed", "searches from the bottom until white"),
    gen.const("downsampling_reversed",str_t, "downsampling_reversed", "searches from the bottom using more efficient down scaling and bluring"),
    gen.const("binary",str_t, "binary", "uses binary search")
  ],
  "An enum to change the field_boundary finder method")

obstacle_detector_enum = gen.enum(
  [
    gen.const("convex",str_t, "convex", "finds obstacles using the difference of the convex and normal field boundary"),
    gen.const("distance",str_t, "distance", "parameters are adjusted for the height of the obstacle in the image and therefore its distance "),
    gen.const("step",str_t, "step", "finds obstacles using the height difference of the normal field boundary")
  ],
  "An enum to change the obstacle detector method")

# The following part creates dummy objects which are dynamicly replaced with the real enums if the vision starts.

color_space_enum = gen.enum([gen.const("dummy",str_t, "dummy", "dummy decription")], "Dummy")

dummy_list = ["dummy"]

fcnn_paths_enum = gen.enum([ gen.const("dummy",str_t, "dummy", "dummy description")], "Dummy")
yolo_darknet_paths_enum = gen.enum([ gen.const("dummy",str_t, "dummy", "dummy description")], "Dummy")
yolo_openvino_paths_enum = gen.enum([ gen.const("dummy",str_t, "dummy", "dummy description")], "Dummy")

##########
# Groups #
##########

group_vision = gen.add_group("Vision", type="tab")
group_ROS = gen.add_group("ROS", type="tab")
group_neural_networks = gen.add_group("Neural Networks", type="tab")
group_color_detector = gen.add_group("Color", type="tab")
group_detector = gen.add_group("Detector", type="tab")

group_neural_network_type = group_detector.add_group("Ball", type="tab")
group_goal = group_detector.add_group("Goal", type="tab")
group_field_boundary_detector = group_detector.add_group("Field Boundary", type="tab")
group_line_detector = group_detector.add_group("Line", type="tab")
group_obstacle_detector = group_detector.add_group("Obstacle", type="tab")

group_field_color_detector = group_color_detector.add_group("Field")
group_hsv_field_color_detector = group_field_color_detector.add_group("HSV")
group_white_color_detector = group_color_detector.add_group("White")
group_red_color_detector = group_color_detector.add_group("Red")
group_blue_color_detector = group_color_detector.add_group("Blue")

group_dynamic_color_space = group_field_color_detector.add_group("DynamicColorSpace")

group_fcnn = group_neural_networks.add_group("FCNN")
group_yolo = group_neural_networks.add_group("YOLO")

group_debug = group_vision.add_group("Debug")

##########
# Params #
##########

group_vision.add("vision_parallelize", bool_t, 0, "Run the neural net and the conventional part in parallel", None)
group_vision.add("vision_blind_threshold", int_t, 0, "Brightness threshold under which the vision thinks, that someone forgot the camera cap", min=0, max=765)

group_ROS.add("ROS_audio_msg_topic", str_t, 0, "ROS topic of the audio message", None)
group_ROS.add("ROS_img_msg_topic", str_t, 0, "ROS topic of the image message", None)
group_ROS.add("ROS_img_msg_queue_size", int_t, 0, "ROS queue size for the image message", min=1, max=20)
group_ROS.add("ROS_fcnn_img_msg_topic", str_t, 0, "ROS topic of the fcnn output message", None)
group_ROS.add("ROS_field_boundary_msg_topic", str_t, 0, "ROS topic of the field boundary message", None)
group_ROS.add("ROS_ball_msg_topic", str_t, 0, "ROS topic of the ball message", None)
group_ROS.add("ROS_goal_posts_msg_topic", str_t, 0, "ROS topic of the goal posts message", None)
group_ROS.add("ROS_obstacle_msg_topic", str_t, 0, "ROS topic of the obstacles message", None)
group_ROS.add("ROS_line_msg_topic", str_t, 0, "ROS topic of the line message", None)
group_ROS.add("ROS_line_mask_msg_topic", str_t, 0, "ROS topic of the line mask message", None)
group_ROS.add("ROS_dynamic_color_space_msg_topic", str_t, 0, "ROS topic of the dynamic color space message", None)
group_ROS.add("ROS_debug_image_msg_topic", str_t, 0, "ROS topic of the debug image message", None)
group_ROS.add("ROS_debug_fcnn_image_msg_topic", str_t, 0, "ROS topic of the FCNN debug image message", None)
group_ROS.add("ROS_white_HSV_mask_image_msg_topic", str_t, 0, "ROS topic of the white HSV color detector mask debug image message", None)
group_ROS.add("ROS_red_HSV_mask_image_msg_topic", str_t, 0, "ROS topic of the red HSV color detector mask debug image message", None)
group_ROS.add("ROS_blue_HSV_mask_image_msg_topic", str_t, 0, "ROS topic of the blue HSV color detector mask debug image message", None)
group_ROS.add("ROS_field_mask_image_msg_topic", str_t, 0, "ROS topic of the field mask debug image message", None)
group_ROS.add("ROS_dynamic_color_space_field_mask_image_msg_topic", str_t, 0, "ROS topic of the dynamic color space field mask debug image message", None)

group_neural_networks.add("neural_network_type", str_t, 0, "The neural network type that should be used (fcnn, yolo_opencv, yolo_darknet or dummy)", "fcnn", edit_method=neural_network_type_enum)

group_yolo.add("yolo_darknet_model_path", str_t, 0, "Name of the yolo model", dummy_list[0], edit_method=yolo_darknet_paths_enum)
group_yolo.add("yolo_openvino_model_path", str_t, 0, "Name of the yolo model", dummy_list[0], edit_method=yolo_openvino_paths_enum)
group_yolo.add("yolo_nms_threshold", double_t, 0, "Yolo: Non maximum suppression threshold", min=0.0, max=1.0)
group_yolo.add("yolo_confidence_threshold", double_t, 0, "Yolo: confidence threshold", min=0.0, max=1.0)

group_fcnn.add("fcnn_model_path", str_t, 0, "Name of the ball fcnn model", dummy_list[0], edit_method=fcnn_paths_enum)
group_fcnn.add("ball_fcnn_threshold", double_t, 0, "Minimal activation for a pixel in the fcnn heatmap to be considered", min=0.0, max=1.0)
group_fcnn.add("ball_fcnn_expand_stepsize", int_t, 0, "Expand stepsize for the ball fcnn clustering", min=1, max=20)
group_fcnn.add("ball_fcnn_pointcloud_stepsize", int_t, 0, "Pointcloud stepsize for the ball fcnn clustering", min=1, max=20)
group_fcnn.add("ball_fcnn_min_ball_diameter", int_t, 0, "Minimum diameter of a ball", min=1, max=50)
group_fcnn.add("ball_fcnn_max_ball_diameter", int_t, 0, "Maximum diameter of a ball", min=1, max=600)
group_fcnn.add("ball_fcnn_candidate_refinement_iteration_count", int_t, 0, "Number of iterations of refinement of ball candidates", min=1,max=100)
group_fcnn.add("ball_fcnn_publish_output", bool_t, 0, "Publish the output of the ball fcnn as RegionOfInterestWithImage", None)
group_fcnn.add("ball_fcnn_publish_field_boundary_offset", int_t, 0, "The offset added to the field_boundary when cropping the fcnn output for publication in pixels", min=1,max=50)

group_neural_network_type.add("ball_candidate_field_boundary_y_offset", int_t, 0, "Threshold in which ball candidates over the field boundary are allowed.", min=0, max=800)
group_neural_network_type.add("ball_candidate_rating_threshold", double_t, 0, "A threshold for the minimum candidate rating", min=0.0, max=1.0)
group_neural_network_type.add("ball_candidate_max_count", int_t, 0, "The maximum number of balls that should be published", min=0, max=50)

group_goal.add("goal_post_field_boundary_y_offset", int_t, 0, "Maximum distance between field boundary and goal post", min=1, max=600)

group_field_color_detector.add("field_color_detector_path", str_t, 0, "Color space for the field color detector", dummy_list[0], edit_method=color_space_enum)

group_hsv_field_color_detector.add("field_color_detector_use_hsv", bool_t, 0, "Should the dummy field HSV detector be used instead", None)
group_hsv_field_color_detector.add("field_color_detector_lower_values_h", int_t, 0, "Lower bound for the field color detector hue", min=0, max=180)
group_hsv_field_color_detector.add("field_color_detector_lower_values_s", int_t, 0, "Lower bound for the field color detector saturation", min=0, max=255)
group_hsv_field_color_detector.add("field_color_detector_lower_values_v", int_t, 0, "Lower bound for the field color detector value/brightness", min=0, max=255)
group_hsv_field_color_detector.add("field_color_detector_upper_values_h", int_t, 0, "Upper bound for the field color detector hue", min=0, max=180)
group_hsv_field_color_detector.add("field_color_detector_upper_values_s", int_t, 0, "Upper bound for the field color detector saturation", min=0, max=255)
group_hsv_field_color_detector.add("field_color_detector_upper_values_v", int_t, 0, "Upper bound for the field color detector value/brightness", min=0, max=255)

group_dynamic_color_space.add("dynamic_color_space_active", bool_t, 0, "Turn dynamic color space ON or OFF", None)
group_dynamic_color_space.add("dynamic_color_space_max_fps", double_t, 0, "Maximum FPS of the dynamic color space node", min=0, max=100)
group_dynamic_color_space.add("dynamic_color_space_queue_max_size", int_t, 0, "Maximum size of queue that holds the latest added colors", min=1, max=100)
group_dynamic_color_space.add("dynamic_color_space_threshold", double_t, 0, "Necessary amount of previously detected color inside the kernel in percentage", min=0.0, max=1.0)
group_dynamic_color_space.add("dynamic_color_space_kernel_radius", int_t, 0, "Radius surrounding the center-element of kernel-matrix, defines relevant surrounding of pixel", min=1, max=100)
group_dynamic_color_space.add("dynamic_color_space_field_boundary_detector_search_method", str_t, 0, "Search method for FieldBoundaryFinder used by DynamicColorSpace (iteration, reversed, binary or dynamic)", "reversed", edit_method=field_boundary_detector_enum)

group_white_color_detector.add("white_color_detector_lower_values_h", int_t, 0, "Lower bound for the white color detector hue", min=0, max=180)
group_white_color_detector.add("white_color_detector_lower_values_s", int_t, 0, "Lower bound for the white color detector saturation", min=0, max=255)
group_white_color_detector.add("white_color_detector_lower_values_v", int_t, 0, "Lower bound for the white color detector value/brightness", min=0, max=255)
group_white_color_detector.add("white_color_detector_upper_values_h", int_t, 0, "Upper bound for the white color detector hue", min=0, max=180)
group_white_color_detector.add("white_color_detector_upper_values_s", int_t, 0, "Upper bound for the white color detector saturation", min=0, max=255)
group_white_color_detector.add("white_color_detector_upper_values_v", int_t, 0, "Upper bound for the white color detector value/brightness", min=0, max=255)
group_white_color_detector.add("white_color_detector_use_color_space", bool_t, 0, "Should the white color detector use a color space or a HSV range", None)
group_white_color_detector.add("white_color_detector_color_space_path", str_t, 0, "Color space for the line color detector", dummy_list[0], edit_method=color_space_enum)


group_red_color_detector.add("red_color_detector_lower_values_h", int_t, 0, "Lower bound for the red color detector hue", min=0, max=180)
group_red_color_detector.add("red_color_detector_lower_values_s", int_t, 0, "Lower bound for the red color detector saturation", min=0, max=255)
group_red_color_detector.add("red_color_detector_lower_values_v", int_t, 0, "Lower bound for the red color detector value/brightness", min=0, max=255)
group_red_color_detector.add("red_color_detector_upper_values_h", int_t, 0, "Upper bound for the red color detector hue", min=0, max=180)
group_red_color_detector.add("red_color_detector_upper_values_s", int_t, 0, "Upper bound for the red color detector saturation", min=0, max=255)
group_red_color_detector.add("red_color_detector_upper_values_v", int_t, 0, "Upper bound for the red color detector value/brightness", min=0, max=255)

group_blue_color_detector.add("blue_color_detector_lower_values_h", int_t, 0, "Lower bound for the blue color detector hue", min=0, max=180)
group_blue_color_detector.add("blue_color_detector_lower_values_s", int_t, 0, "Lower bound for the blue color detector saturation", min=0, max=255)
group_blue_color_detector.add("blue_color_detector_lower_values_v", int_t, 0, "Lower bound for the blue color detector value/brightness", min=0, max=255)
group_blue_color_detector.add("blue_color_detector_upper_values_h", int_t, 0, "Upper bound for the blue color detector hue", min=0, max=180)
group_blue_color_detector.add("blue_color_detector_upper_values_s", int_t, 0, "Upper bound for the blue color detector saturation", min=0, max=255)
group_blue_color_detector.add("blue_color_detector_upper_values_v", int_t, 0, "Upper bound for the blue color detector value/brightness", min=0, max=255)

group_field_boundary_detector.add("field_boundary_detector_search_method", str_t, 0, "Method for finding the field boundary (iteration, reversed, downsampling_reversed, binary, dynamic)", "iteration", edit_method=field_boundary_detector_enum)
group_field_boundary_detector.add("field_boundary_detector_vertical_steps", int_t, 0, "Number of steps on each scanline", min=1, max=480)
group_field_boundary_detector.add("field_boundary_detector_horizontal_steps", int_t, 0, "Number of scanlines", min=1, max=640)
group_field_boundary_detector.add("field_boundary_detector_roi_height", int_t, 0, "Region Of Interest height in which we are looking for green", min=1, max=100)
group_field_boundary_detector.add("field_boundary_detector_roi_width", int_t, 0, "Region Of Interest width in which we are looking for green", min=1, max=100)
group_field_boundary_detector.add("field_boundary_detector_roi_increase", double_t, 0, "Value that increases the region of interest if it is located lower in the image", min=0, max=1.0)
group_field_boundary_detector.add("field_boundary_detector_green_threshold", int_t, 0, "Threshold of green in the area covered by the kernel", min=0, max=1000)
group_field_boundary_detector.add("field_boundary_detector_head_tilt_threshold", int_t, 0, "Threshold for the dynamic search method, that describes the head angle at which we are switching between the iteration and the reversed search method.", min=0, max=90)

group_line_detector.add("line_detector_field_boundary_offset", int_t, 0, "Threshold in which we are also searching for lines over the field boundary", min=-1000, max=1000)
group_line_detector.add("line_detector_linepoints_range", int_t, 0, "Number of line points", min=0, max=20000)
group_line_detector.add("line_detector_use_line_points", bool_t, 0, "Calculate and publish the line points", None)
group_line_detector.add("line_detector_use_line_mask", bool_t, 0, "Calculate and publish the line mask", None)

group_obstacle_detector.add("obstacle_active", bool_t, 0, "Enables the obstacle detection", None)
group_obstacle_detector.add("obstacle_finder_method", str_t, 0, "Method for the obstacle finder (distance, convex or step)", "distance", edit_method=obstacle_detector_enum)
group_obstacle_detector.add("obstacle_color_threshold", int_t, 0, "An obstacle is defined as blue/red if it contains more blue or red than this threshold", min=0, max=255)
group_obstacle_detector.add("obstacle_white_threshold", int_t, 0, "An obstacle that contains more white than this threshold and is not colored, is an goalpost in the conventional approach", min=0, max=255)
group_obstacle_detector.add("obstacle_field_boundary_diff_threshold", int_t, 0, "Minimal distance between detected and convex field boundary to accept it as obstacle", min=0, max=200)
group_obstacle_detector.add("obstacle_candidate_field_boundary_offset", int_t, 0, "Fixed height of obstacles above the field boundary", min=0, max=500)
group_obstacle_detector.add("obstacle_candidate_min_width", int_t, 0, "Minimum width of an obstacle", min=1, max=640)
group_obstacle_detector.add("obstacle_candidate_max_width", int_t, 0, "Maximum width of an obstacle", min=1, max=640)
group_obstacle_detector.add("obstacle_finder_step_length", int_t, 0, "Length of an object detection step along the field boundary", min=1, max=640)
group_obstacle_detector.add("obstacle_finder_value_increase", double_t, 0, "Factor of the impact of the height of the field boundary on the distance threshold", min=0, max=10.0)

group_debug.add("vision_publish_debug_image", bool_t, 0, "Publish debug image message", None)
group_debug.add("ball_fcnn_publish_debug_img", bool_t, 0, "Publish the fcnn heatmap image for debug purposes", None)
group_debug.add("vision_publish_HSV_mask_image", bool_t, 0, "Publish all three HSV color detector mask image messages for debug purposes", None)
group_debug.add("vision_publish_field_mask_image", bool_t, 0, "Publish field mask image message for debug purposes", None)
group_debug.add("caching", bool_t, 0, "Used to deactivate caching for profiling reasons", None)

exit(gen.generate(PACKAGE, "bitbots_vision", "Vision"))
