#!/usr/bin/env python
PACKAGE = "bitbots_vision"

from dynamic_reconfigure.parameter_generator_catkin import *
import rospkg

rospack = rospkg.RosPack()
package_path = rospack.get_path('bitbots_vision')

gen = ParameterGenerator()

ball_detector_enum = gen.enum([ gen.const("fcnn",      str_t, "fcnn", "fcnn classifier"),
                        gen.const("yolo_opencv",      str_t, "yolo_opencv", "yolo object detection (opencv implementation)"),
                        gen.const("yolo_darknet",      str_t, "yolo_darknet", "yolo object detection (darknet implementation)"),
                       gen.const("dummy",      str_t, "dummy", "no balls will be detected")],
                     "An enum to set the ball classifier")

field_boundary_detector_enum = gen.enum([ gen.const("iteration",      str_t, "iteration", "searches from the top until green"),
                       gen.const("dynamic",     str_t, "dynamic", "uses head_joint_state messages to switch between methods"),
                       gen.const("reversed",     str_t, "reversed", "searches from the bottom until white"),
                       gen.const("binary",      str_t, "binary", "uses binary search")],
                     "An enum to change the field_boundary finder method")

obstacle_detector_enum = gen.enum([ gen.const("convex",      str_t, "convex", "finds obstacles using the difference of the convex and normal field boundary"),
                       gen.const("distance",     str_t, "distance", "parameters are adjusted for the height of the obstacle in the image and therefore its distance "),
                       gen.const("step",      str_t, "step", "finds obstacles using the height difference of the normal field boundary")],
                     "An enum to change the obstacle detector method")

field_color_space_enum = gen.enum([ gen.const("dummy",      str_t, "dummy", "dummy decription")], "Dummy")

dummy_list = ["dummy"]

fcnn_paths_enum = gen.enum([ gen.const("dummy",      str_t, "dummy", "dummy decription")], "Dummy")
yolo_paths_enum = gen.enum([ gen.const("dummy",      str_t, "dummy", "dummy decription")], "Dummy")

group_vision = gen.add_group("vision", type="tab")
group_ROS = gen.add_group("ROS", type="tab")
group_neural_networks = gen.add_group("Neural Networks", type="tab")
group_detector = gen.add_group("detector", type="tab")
group_dynamic_color_space = gen.add_group("DynamicColorSpace", type="tab")

group_color_detector = group_detector.add_group("color_detector", type="tab")
group_line_detector = group_detector.add_group("line_detector", type="tab")
group_field_boundary_detector = group_detector.add_group("field_boundary_detector", type="tab")
group_obstacle_detector = group_detector.add_group("obstacle_detector", type="tab")

group_field_color_detector = group_color_detector.add_group("field_color_detector")
group_white_color_detector = group_color_detector.add_group("white_color_detector")
group_red_color_detector = group_color_detector.add_group("red_color_detector")
group_blue_color_detector = group_color_detector.add_group("blue_color_detector")

group_neural_networks.add("ball_fcnn_publish_debug_img", bool_t, 0, "toggles publishing of the fcnn heatmap image for debug purposes", None)
group_neural_networks.add("fcnn_model_path", str_t, 0, "fcnn_model_path", dummy_list[0], edit_method=fcnn_paths_enum)
group_neural_networks.add("yolo_model_path", str_t, 0, "yolo_model_path", dummy_list[0], edit_method=yolo_paths_enum)
group_neural_networks.add("ball_fcnn_threshold", double_t, 0, "ball_fcnn_threshold", min=0.0, max=1.0)
group_neural_networks.add("ball_fcnn_expand_stepsize", int_t, 0, "ball_fcnn_expand_stepsize", min=1, max=20)
group_neural_networks.add("ball_fcnn_pointcloud_stepsize", int_t, 0, "ball_fcnn_pointcloud_stepsize", min=1, max=20)
group_neural_networks.add("ball_fcnn_shuffle_candidate_list", bool_t, 0, "ball_fcnn_shuffle_candidate_list")
group_neural_networks.add("ball_fcnn_min_ball_diameter", int_t, 0, "ball_fcnn_min_ball_diameter", min=1, max=50)
group_neural_networks.add("ball_fcnn_max_ball_diameter", int_t, 0, "ball_fcnn_max_ball_diameter", min=1, max=600)
group_neural_networks.add("ball_fcnn_candidate_refinement_iteration_count", int_t, 0, "ball_fcnn_candidate_refinement_iteration_count", min=1,max=100)
group_neural_networks.add("ball_fcnn_publish_output", bool_t, 0, "publish the output of the ball fcnn as ImageWithCRegionOfInterest", None)
group_neural_networks.add("ball_fcnn_publish_field_boundary_offset", int_t, 0, "the offset added to the field_boundary when cropping the fcnn output for publication in pixels", min=1,max=50)

group_field_color_detector.add("field_color_detector_path", str_t, 0, "field_color_detector_path", dummy_list[0], edit_method=field_color_space_enum)
group_field_color_detector.add("field_color_detector_path_sim", str_t, 0, "field_color_detector_path_sim", dummy_list[0],  edit_method=field_color_space_enum)
group_field_color_detector.add("field_color_detector_use_dummy_green", bool_t, 0, "field_color_detector_use_dummy_green", None)
group_field_color_detector.add("field_color_detector_dummy_lower_values_h", int_t, 0, "field_color_detector_dummy_lower_values_h", min=0, max=180)
group_field_color_detector.add("field_color_detector_dummy_lower_values_s", int_t, 0, "field_color_detector_dummy_lower_values_s", min=0, max=255)
group_field_color_detector.add("field_color_detector_dummy_lower_values_v", int_t, 0, "field_color_detector_dummy_lower_values_v", min=0, max=255)
group_field_color_detector.add("field_color_detector_dummy_upper_values_h", int_t, 0, "field_color_detector_dummy_upper_values_h", min=0, max=180)
group_field_color_detector.add("field_color_detector_dummy_upper_values_s", int_t, 0, "field_color_detector_dummy_upper_values_s", min=0, max=255)
group_field_color_detector.add("field_color_detector_dummy_upper_values_v", int_t, 0, "field_color_detector_dummy_upper_values_v", min=0, max=255)

group_red_color_detector.add("red_color_detector_lower_values_h", int_t, 0, "red_color_detector_lower_values_h", min=0, max=180)
group_red_color_detector.add("red_color_detector_lower_values_s", int_t, 0, "red_color_detector_lower_values_s", min=0, max=255)
group_red_color_detector.add("red_color_detector_lower_values_v", int_t, 0, "red_color_detector_lower_values_v", min=0, max=255)
group_red_color_detector.add("red_color_detector_upper_values_h", int_t, 0, "red_color_detector_upper_values_h", min=0, max=180)
group_red_color_detector.add("red_color_detector_upper_values_s", int_t, 0, "red_color_detector_upper_values_s", min=0, max=255)
group_red_color_detector.add("red_color_detector_upper_values_v", int_t, 0, "red_color_detector_upper_values_v", min=0, max=255)

group_blue_color_detector.add("blue_color_detector_lower_values_h", int_t, 0, "blue_color_detector_lower_values_h", min=0, max=180)
group_blue_color_detector.add("blue_color_detector_lower_values_s", int_t, 0, "blue_color_detector_lower_values_s", min=0, max=255)
group_blue_color_detector.add("blue_color_detector_lower_values_v", int_t, 0, "blue_color_detector_lower_values_v", min=0, max=255)
group_blue_color_detector.add("blue_color_detector_upper_values_h", int_t, 0, "blue_color_detector_upper_values_h", min=0, max=180)
group_blue_color_detector.add("blue_color_detector_upper_values_s", int_t, 0, "blue_color_detector_upper_values_s", min=0, max=255)
group_blue_color_detector.add("blue_color_detector_upper_values_v", int_t, 0, "blue_color_detector_upper_values_v", min=0, max=255)

group_white_color_detector.add("white_color_detector_lower_values_h", int_t, 0, "white_color_detector_lower_values_h", min=0, max=180)
group_white_color_detector.add("white_color_detector_lower_values_s", int_t, 0, "white_color_detector_lower_values_s", min=0, max=255)
group_white_color_detector.add("white_color_detector_lower_values_v", int_t, 0, "white_color_detector_lower_values_v", min=0, max=255)
group_white_color_detector.add("white_color_detector_upper_values_h", int_t, 0, "white_color_detector_upper_values_h", min=0, max=180)
group_white_color_detector.add("white_color_detector_upper_values_s", int_t, 0, "white_color_detector_upper_values_s", min=0, max=255)
group_white_color_detector.add("white_color_detector_upper_values_v", int_t, 0, "white_color_detector_upper_values_v", min=0, max=255)

group_field_boundary_detector.add("field_boundary_detector_search_method", str_t, 0, "field_boundary_detector_search_method", "iteration", edit_method=field_boundary_detector_enum)
group_field_boundary_detector.add("field_boundary_detector_vertical_steps", int_t, 0, "field_boundary_detector_vertical_steps", min=1, max=480)
group_field_boundary_detector.add("field_boundary_detector_horizontal_steps", int_t, 0, "field_boundary_detector_horizontal_steps", min=1, max=640)
group_field_boundary_detector.add("field_boundary_detector_roi_height", int_t, 0, "field_boundary_detector_roi_height", min=1, max=100)
group_field_boundary_detector.add("field_boundary_detector_roi_width", int_t, 0, "field_boundary_detector_roi_width", min=1, max=100)
group_field_boundary_detector.add("field_boundary_detector_roi_increase", double_t, 0, "field_boundary_detector_roi_increase", min=0, max=1.0)
group_field_boundary_detector.add("field_boundary_detector_green_threshold", int_t, 0, "field_boundary_detector_green_threshold", min=0, max=1000)
group_field_boundary_detector.add("field_boundary_detector_precision_pix", int_t, 0, "field_boundary_detector_precision_pix", min=1, max=20)
group_field_boundary_detector.add("field_boundary_detector_min_precision_pix", int_t, 0, "field_boundary_detector_min_precision_pix", min=1, max=20)
group_field_boundary_detector.add("field_boundary_detector_head_tilt_threshold", int_t, 0, "field_boundary_detector_head_joint_threshold", min=0, max=90)

group_vision.add("vision_publish_debug_image", bool_t, 0, "Publish debug image message", None)
group_vision.add("vision_publish_field_mask_image", bool_t, 0, "Publish field mask image message for debug purposes", None)
group_vision.add("vision_parallelize", bool_t, 0, "vision_parallelize", None)
group_vision.add("vision_use_sim_color", bool_t, 0, "vision_use_sim_color", None)
group_vision.add("vision_ball_detector", str_t, 0, "vision_ball_detector", "fcnn", edit_method=ball_detector_enum)
group_vision.add("vision_ball_candidate_field_boundary_y_offset", int_t, 0, "vision_ball_candidate_field_boundary_y_offset", min=0, max=20)
group_vision.add("vision_ball_candidate_rating_threshold", double_t, 0, "vision_ball_candidate_rating_threshold", min=0.0, max=1.0)
group_vision.add("vision_blind_threshold", int_t, 0, "vision_blind_threshold", min=0, max=765)

group_obstacle_detector.add("obstacle_finder_method", str_t, 0, "obstacle_finder_method", "convex", edit_method=obstacle_detector_enum)
group_obstacle_detector.add("obstacle_color_threshold", int_t, 0, "obstacle_color_threshold", min=0, max=255)
group_obstacle_detector.add("obstacle_white_threshold", int_t, 0, "obstacle_white_threshold", min=0, max=255)
group_obstacle_detector.add("obstacle_field_boundary_diff_threshold", int_t, 0, "obstacle_field_boundary_diff_threshold", min=0, max=200)
group_obstacle_detector.add("obstacle_candidate_field_boundary_offset", int_t, 0, "obstacle_candidate_field_boundary_offset", min=0, max=500)
group_obstacle_detector.add("obstacle_candidate_min_width", int_t, 0, "obstacle_candidate_min_width", min=1, max=640)
group_obstacle_detector.add("obstacle_candidate_max_width", int_t, 0, "obstacle_candidate_max_width", min=1, max=640)
group_obstacle_detector.add("obstacle_finder_step_length", int_t, 0, "obstacle_finder_step_length", min=1, max=640)
group_obstacle_detector.add("obstacle_finder_value_increase", double_t, 0, "obstacle_finder_value_increase", min=0, max=10.0)

group_line_detector.add("line_detector_field_boundary_offset", int_t, 0, "line_detector_field_boundary_offset", min=0, max=200)
group_line_detector.add("line_detector_linepoints_range", int_t, 0, "line_detector_linepoints_range", min=0, max=20000)
group_line_detector.add("line_detector_blur_kernel_size", int_t, 0, "line_detector_blur_kernel_size", min=1, max=30)

group_ROS.add("ROS_img_msg_topic", str_t, 0, "ROS_img_msg_topic", None)
group_ROS.add("ROS_img_queue_size", int_t, 0, "ROS_img_queue_size", min=1, max=20)
group_ROS.add("ROS_ball_msg_topic", str_t, 0, "ROS_ball_msg_topic", None)
group_ROS.add("ROS_fcnn_img_msg_topic", str_t, 0, "ROS_fcnn_img_msg_topic", None)
group_ROS.add("ROS_obstacle_msg_topic", str_t, 0, "ROS_obstacle_msg_topic", None)
group_ROS.add("ROS_field_boundary_msg_topic", str_t, 0, "ROS_field_boundary_msg_topic", None)
group_ROS.add("ROS_goal_msg_topic", str_t, 0, "ROS_goal_msg_topic", None)
group_ROS.add("ROS_line_msg_topic", str_t, 0, "ROS_line_msg_topic", None)
group_ROS.add("ROS_non_line_msg_topic", str_t, 0, "ROS_non_line_msg_topic", None)
group_ROS.add("ROS_dynamic_color_space_msg_topic", str_t, 0, "Specify topic name for publishing color spaces of dynamic color space node", None)
group_ROS.add("ROS_debug_image_msg_topic", str_t, 0, "Specify topic name for publishing debug images, controll publishing with 'vision_publish_debug_image'", None)
group_ROS.add("ROS_debug_fcnn_image_msg_topic", str_t, 0, "Specify topic name for publishing debug fcnn images, controll publishing with 'ball_fcnn_publish_debug_img'", None)
group_ROS.add("ROS_field_mask_image_msg_topic", str_t, 0, "Specify topic name for publishing field mask images, controll publishing with 'vision_publish_field_mask_image'", None)
group_ROS.add("ROS_dynamic_color_space_field_mask_image_msg_topic", str_t, 0, "Specify topic name for publishing field mask images, controll publishing with 'dynamic_color_space_publish_field_mask_image'", None)
group_ROS.add("ROS_head_joint_msg_topic", str_t, 0, "ROS_head_joint_msg_topic", None)
group_ROS.add("ROS_head_joint_state_queue_size", int_t, 0, "ROS_head_joint_state_queue_size", min=1, max=20)

group_dynamic_color_space.add("dynamic_color_space_active", bool_t, 0, "Turn dynamic color space ON or OFF", None)
group_dynamic_color_space.add("dynamic_color_space_publish_field_mask_image", bool_t, 0, "Publish dynamic color space field mask image message for debug purposes", None)
group_dynamic_color_space.add("dynamic_color_space_queue_max_size", int_t, 0, "maximum size of queue that holds the latest added colors", min=1, max=100)
group_dynamic_color_space.add("dynamic_color_space_threshold", double_t, 0, "necessary amount of previously detected color in percentage", min=0.0, max=1.0)
group_dynamic_color_space.add("dynamic_color_space_kernel_radius", int_t, 0, "radius surrounding the center-element of kernel-matrix, defines relevant surrounding of pixel", min=1, max=100)
group_dynamic_color_space.add("dynamic_color_space_field_boundary_detector_search_method", str_t, 0, "Search method for FieldBoundaryFinder used by DynamicColorSpace", "reversed", edit_method=field_boundary_detector_enum)

exit(gen.generate(PACKAGE, "bitbots_vision", "Vision"))
