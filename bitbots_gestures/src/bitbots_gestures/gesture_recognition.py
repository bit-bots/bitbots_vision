#! /usr/bin/env python3
import os
import rospy
import cv2 as cv
from cv_bridge import CvBridge
from sensor_msgs.msg import Image

LOGGER_NAME = "gesture_recognition"

try:
    from openvino.inference_engine import IENetwork, IECore
except ImportError:
    rospy.logerr(
        "Not able to run OpenPose on the Intel NCS2 TPU! The OpenVINO SDK should be installed if you intend to run OpenPose on the TPU",
        logger_name=LOGGER_NAME)

BODY_PARTS = {"Nose": 0, "Neck": 1, "RShoulder": 2, "RElbow": 3, "RWrist": 4,
              "LShoulder": 5, "LElbow": 6, "LWrist": 7, "RHip": 8, "RKnee": 9,
              "RAnkle": 10, "LHip": 11, "LKnee": 12, "LAnkle": 13, "REye": 14,
              "LEye": 15, "REar": 16, "LEar": 17, "Background": 18}

POSE_PAIRS = [["Neck", "RShoulder"], ["Neck", "LShoulder"], ["RShoulder", "RElbow"],
              ["RElbow", "RWrist"], ["LShoulder", "LElbow"], ["LElbow", "LWrist"],
              ["Neck", "RHip"], ["RHip", "RKnee"], ["RKnee", "RAnkle"], ["Neck", "LHip"],
              ["LHip", "LKnee"], ["LKnee", "LAnkle"], ["Neck", "Nose"], ["Nose", "REye"],
              ["REye", "REar"], ["Nose", "LEye"], ["LEye", "LEar"]]

THRESHOLD = 0.5


class OpenPose:
    def __init__(self, model_path):
        # Create model file paths
        model_xml = os.path.join(model_path, "human-pose-estimation-0001.xml")
        model_bin = os.path.join(model_path, "human-pose-estimation-0001.bin")

        # Plugin initialization
        rospy.logdebug("Creating Inference Engine...", logger_name=LOGGER_NAME)

        try:
            ie = IECore()
        except NameError:
            rospy.logerr("Please install/source OpenVino environment to use the NCS2 OpenPose Handler.",
                         logger_name=LOGGER_NAME)
            raise

        # Reading the IR generated by the Model Optimizer (.xml and .bin files)
        rospy.logdebug("Loading network files:\n\t{}\n\t{}".format(model_xml, model_bin), logger_name=LOGGER_NAME)
        self._net = IENetwork(model=model_xml, weights=model_bin)

        # Preparing network inputs
        rospy.logdebug("Preparing inputs", logger_name=LOGGER_NAME)
        self._input_blob = next(iter(self._net.inputs))

        #  Defaulf batch_size is 1
        self._net.batch_size = 1

        # Read and pre-process input images
        self._n, self._c, self._h, self._w = self._net.inputs[self._input_blob].shape

        # Device type
        device = "MYRIAD"

        # Loading model to the plugin
        rospy.logdebug("Loading model to the plugin", logger_name=LOGGER_NAME)
        self._exec_net = ie.load_network(network=self._net, num_requests=2, device_name=device)

    def predict(self, image):
        rospy.logdebug("Starting inference...", logger_name=LOGGER_NAME)

        # Set request id for the stick. Since we only make one call at a time, we use a static parameter.
        request_id = 1
        # Resize image to open pose input size
        image_resized = cv.resize(image, (self._w, self._h))

        # resize input_frame to network size
        in_frame = image_resized.transpose((2, 0, 1))  # Change data layout from HWC to CHW
        in_frame = in_frame.reshape((self._n, self._c, self._h, self._w))

        # Start inference
        self._exec_net.start_async(request_id=request_id, inputs={self._input_blob: in_frame})


        # Create barrier. This lets all following processing steps wait until the prediction is calculated.
        if self._exec_net.requests[request_id].wait(-1) == 0:
            # Get output
            output = self._exec_net.requests[request_id].outputs
            pairwise_relations = output["Mconv7_stage2_L1"]
            keypoint_heatmaps = output["Mconv7_stage2_L2"]

            points = []
            for i in range(len(BODY_PARTS)):
                # Slice heatmap of corresponding body's part.
                heatMap = keypoint_heatmaps[0, i, :, :]

                # Originally, we try to find all the local maximums. To simplify a sample
                # we just find a global one. However only a single pose at the same time
                # could be detected this way.
                _, conf, _, point = cv.minMaxLoc(heatMap)
                x = (self._w * point[0]) / keypoint_heatmaps.shape[3]
                y = (self._h * point[1]) / keypoint_heatmaps.shape[2]

                # Add a point if it's confidence is higher than threshold.
                points.append((int(x), int(y)) if conf > THRESHOLD else None)

            for pair in POSE_PAIRS:
                partFrom = pair[0]
                partTo = pair[1]
                assert (partFrom in BODY_PARTS)
                assert (partTo in BODY_PARTS)

                idFrom = BODY_PARTS[partFrom]
                idTo = BODY_PARTS[partTo]

                if points[idFrom] and points[idTo]:
                    cv.line(image_resized, points[idFrom], points[idTo], (0, 255, 0), 3)
                    cv.ellipse(image_resized, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)
                    cv.ellipse(image_resized, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)

            return image_resized
            # for item in output.keys():
            #    print(item)


if __name__ == "__main__":
    openpose = OpenPose("/home/bitbots/wolfgang_ws/src/bitbots_vision/bitbots_gestures/models")

    cv_bridge = CvBridge()

    pub = rospy.Publisher("/gesture_image", Image, queue_size=1)

    image_msg = None


    def image_cb(msg: Image):
        global image_msg
        image_msg = msg


    rospy.init_node("gestures")
    sub = rospy.Subscriber("/image_raw", Image, image_cb, queue_size=1, tcp_nodelay=True)

    while not rospy.is_shutdown():
        if image_msg is not None:
            image = cv_bridge.imgmsg_to_cv2(image_msg, 'bgr8')
            image_msg = None
            debug_image = openpose.predict(image)
            debug_msg = cv_bridge.cv2_to_imgmsg(debug_image, 'bgr8')
            pub.publish(debug_msg)
